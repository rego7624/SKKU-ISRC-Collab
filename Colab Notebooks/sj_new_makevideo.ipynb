{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"sj_new_makevideo.ipynb","provenance":[{"file_id":"15Yb6NBZecwlAxEbmFmz3qIB1Pqwk2xnQ","timestamp":1582041332698}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"2OBNjwlEw3MV","colab_type":"code","colab":{}},"source":["#CTRL + Enter == 셀 실행\n","#Alt + Enter == 셀 실행 후 생성\n","#Shift + Enter == 셀 실행 후 다음 셀로 넘어감\n","\n","#스마트폰 촬영 시 가로캠으로 얼굴이 꽉차지 않게 찍는 것을 권장함"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iYGj_pyIw4sc","colab_type":"code","outputId":"1012cc26-3344-40b9-d26d-2e91ccbed79b","executionInfo":{"status":"ok","timestamp":1582044431445,"user_tz":-540,"elapsed":2167,"user":{"displayName":"my bicker","photoUrl":"","userId":"06111982675229710447"}},"colab":{"base_uri":"https://localhost:8080/","height":62}},"source":["#구글드라이브 연동\n","from google.colab import drive\n","\n","drive.mount('/content/drive/', force_remount = True)\n","\n","\"\"\"\n","링크 클릭 후 뜨는 코드 붙여넣기\n","\"\"\""],"execution_count":8,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'\\n링크 클릭 후 뜨는 코드 붙여넣기\\n'"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"RSrsw2oyw6vf","colab_type":"code","outputId":"487735e7-4f86-4eb0-df5b-a7dd10d3b162","executionInfo":{"status":"ok","timestamp":1582044044412,"user_tz":-540,"elapsed":25495,"user":{"displayName":"my bicker","photoUrl":"","userId":"06111982675229710447"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!cd /content/drive/My\\ Drive/few-shot-vid2vid/ && pip install -r requirements.txt && python test.py --targetInput kimjeong.jpg --faceInput eye_test.mp4 --output kimjeong_to_eye.avi --name face --dataset_mode fewshot_face --adaptive_spade --warp_ref --spade_combine --checkpoints_dir checkpoints\n","\n","#dataset/target/target_images에 '파일명.jpg' 넣고 --targetinput 파일명.jpg\n","#내 드라이브 가장 바깥에 '파일명.mp4' 넣고 --faceInput 파일명.mp4\n","#--output 파일명.avi 실행 후 datasets/output에서 확인\n","\n","\"\"\"\n","<참고>\n","*처음 넣은 face video일 경우 make dataset 후 한 번 더 실행\n","\n","*영상 제작 시\n","...\n","process image... ['datasets/face/face_images/00/094.jpg']\n","process image... ['datasets/face/face_images/00/095.jpg']\n","process image... ['datasets/face/face_images/00/096.jpg']\n","...\n","\n","*영상 제작 후\n","done\n","\n","*실행 시 오류가 안떠도 위 메세지 안보이면 잘못된 것!\n","\"\"\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.4.0)\n","Requirement already satisfied: torchvision==0.4.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (0.4.2)\n","Requirement already satisfied: face-alignment==1.0.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (1.0.0)\n","Requirement already satisfied: matplotlib==2.2.5 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 4)) (2.2.5)\n","Requirement already satisfied: numpy==1.16.6 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.16.6)\n","Requirement already satisfied: opencv-python==4.1.2.30 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: Pillow==6.2.2 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (6.2.2)\n","Requirement already satisfied: dominate in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 8)) (2.4.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 9)) (2.21.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision==0.4.2->-r requirements.txt (line 2)) (1.12.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from face-alignment==1.0.0->-r requirements.txt (line 3)) (4.28.1)\n","Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from face-alignment==1.0.0->-r requirements.txt (line 3)) (1.4.1)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.6/dist-packages (from face-alignment==1.0.0->-r requirements.txt (line 3)) (0.16.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.5->-r requirements.txt (line 4)) (2.4.6)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.5->-r requirements.txt (line 4)) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.5->-r requirements.txt (line 4)) (2.6.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.5->-r requirements.txt (line 4)) (0.10.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib==2.2.5->-r requirements.txt (line 4)) (1.1.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 9)) (2019.11.28)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 9)) (2.8)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment==1.0.0->-r requirements.txt (line 3)) (2.4.1)\n","Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment==1.0.0->-r requirements.txt (line 3)) (1.1.1)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image->face-alignment==1.0.0->-r requirements.txt (line 3)) (2.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib==2.2.5->-r requirements.txt (line 4)) (45.1.0)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image->face-alignment==1.0.0->-r requirements.txt (line 3)) (4.4.1)\n","CustomDatasetDataLoader\n","bye\n","dataset [FaceDataset] was created\n","---------- Networks initialized -------------\n","---------- Optimizers initialized -------------\n","network loaded from checkpoints/face/latest_net_G.pth\n","model [Vid2VidModel] was created\n","first image\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2705: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n","  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n","/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2506: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n","process image... ['datasets/face/face_images/eye_test/00000.jpg']\n","process image... ['datasets/face/face_images/eye_test/00001.jpg']\n","process image... ['datasets/face/face_images/eye_test/00002.jpg']\n","process image... ['datasets/face/face_images/eye_test/00003.jpg']\n","process image... ['datasets/face/face_images/eye_test/00004.jpg']\n","process image... ['datasets/face/face_images/eye_test/00005.jpg']\n","process image... ['datasets/face/face_images/eye_test/00006.jpg']\n","process image... ['datasets/face/face_images/eye_test/00007.jpg']\n","process image... ['datasets/face/face_images/eye_test/00008.jpg']\n","process image... ['datasets/face/face_images/eye_test/00009.jpg']\n","process image... ['datasets/face/face_images/eye_test/00010.jpg']\n","process image... ['datasets/face/face_images/eye_test/00011.jpg']\n","process image... ['datasets/face/face_images/eye_test/00012.jpg']\n","process image... ['datasets/face/face_images/eye_test/00013.jpg']\n","process image... ['datasets/face/face_images/eye_test/00014.jpg']\n","process image... ['datasets/face/face_images/eye_test/00015.jpg']\n","process image... ['datasets/face/face_images/eye_test/00016.jpg']\n","process image... ['datasets/face/face_images/eye_test/00017.jpg']\n","process image... ['datasets/face/face_images/eye_test/00018.jpg']\n","process image... ['datasets/face/face_images/eye_test/00019.jpg']\n","process image... ['datasets/face/face_images/eye_test/00020.jpg']\n","process image... ['datasets/face/face_images/eye_test/00021.jpg']\n","process image... ['datasets/face/face_images/eye_test/00022.jpg']\n","process image... ['datasets/face/face_images/eye_test/00023.jpg']\n","process image... ['datasets/face/face_images/eye_test/00024.jpg']\n","process image... ['datasets/face/face_images/eye_test/00025.jpg']\n","process image... ['datasets/face/face_images/eye_test/00026.jpg']\n","process image... ['datasets/face/face_images/eye_test/00027.jpg']\n","process image... ['datasets/face/face_images/eye_test/00028.jpg']\n","process image... ['datasets/face/face_images/eye_test/00029.jpg']\n","process image... ['datasets/face/face_images/eye_test/00030.jpg']\n","process image... ['datasets/face/face_images/eye_test/00031.jpg']\n","process image... ['datasets/face/face_images/eye_test/00032.jpg']\n","process image... ['datasets/face/face_images/eye_test/00033.jpg']\n","process image... ['datasets/face/face_images/eye_test/00034.jpg']\n","process image... ['datasets/face/face_images/eye_test/00035.jpg']\n","process image... ['datasets/face/face_images/eye_test/00036.jpg']\n","process image... ['datasets/face/face_images/eye_test/00037.jpg']\n","process image... ['datasets/face/face_images/eye_test/00038.jpg']\n","process image... ['datasets/face/face_images/eye_test/00039.jpg']\n","process image... ['datasets/face/face_images/eye_test/00040.jpg']\n","process image... ['datasets/face/face_images/eye_test/00041.jpg']\n","process image... ['datasets/face/face_images/eye_test/00042.jpg']\n","process image... ['datasets/face/face_images/eye_test/00043.jpg']\n","process image... ['datasets/face/face_images/eye_test/00044.jpg']\n","process image... ['datasets/face/face_images/eye_test/00045.jpg']\n","process image... ['datasets/face/face_images/eye_test/00046.jpg']\n","process image... ['datasets/face/face_images/eye_test/00047.jpg']\n","process image... ['datasets/face/face_images/eye_test/00048.jpg']\n","process image... ['datasets/face/face_images/eye_test/00049.jpg']\n","process image... ['datasets/face/face_images/eye_test/00050.jpg']\n","process image... ['datasets/face/face_images/eye_test/00051.jpg']\n","process image... ['datasets/face/face_images/eye_test/00052.jpg']\n","process image... ['datasets/face/face_images/eye_test/00053.jpg']\n","process image... ['datasets/face/face_images/eye_test/00054.jpg']\n","process image... ['datasets/face/face_images/eye_test/00055.jpg']\n","process image... ['datasets/face/face_images/eye_test/00056.jpg']\n","process image... ['datasets/face/face_images/eye_test/00057.jpg']\n","process image... ['datasets/face/face_images/eye_test/00058.jpg']\n","process image... ['datasets/face/face_images/eye_test/00059.jpg']\n","process image... ['datasets/face/face_images/eye_test/00060.jpg']\n","process image... ['datasets/face/face_images/eye_test/00061.jpg']\n","process image... ['datasets/face/face_images/eye_test/00062.jpg']\n","process image... ['datasets/face/face_images/eye_test/00063.jpg']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cl7fMk_I1tya","colab_type":"code","colab":{}},"source":["!cd /content/drive/My\\ Drive/few-shot-vid2vid/ && pip install -r requirements.txt && python test.py --targetInput kimjeong.jpg --faceInput plask_200.mp4 --output kimjeong_to_plask.avi --name face --dataset_mode fewshot_face --adaptive_spade --warp_ref --spade_combine --checkpoints_dir checkpoints\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"hx8dgTaRM6ZF","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}